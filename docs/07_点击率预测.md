# 📖 点击率预测

> 广告系统的核心算法

---

## 🎯 什么是点击率预测？

**点击率预测**（CTR Prediction）是预测用户在看到某个广告后点击的概率。

### **为什么 CTR 预测重要？**

```
广告排序依据 eCPM：

eCPM = CTR × bid × 1000

┌─────────────────────────────────────────────────────────────────┐
│                                                                 │
│   广告A：出价 ¥5，预估CTR = 1%                                   │
│         eCPM = 1% × 5 × 1000 = ¥50                              │
│                                                                 │
│   广告B：出价 ¥3，预估CTR = 2%                                   │
│         eCPM = 2% × 3 × 1000 = ¥60                              │
│                                                                 │
│   结论：广告B虽然出价低，但因为CTR高，排名更靠前                   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘

CTR预测的准确性直接影响：
• 广告排序的合理性
• 平台收入
• 广告主ROI
• 用户体验
```

---

## 📊 问题建模

### **点击预测的数学表达**

```
输入：广告(a), 用户(u), 上下文(c)
输出：点击概率 P(click=1 | a, u, c)

建模为二分类问题：
• 正样本：展示后发生点击
• 负样本：展示后未点击

特点：
• 样本严重不均衡（CTR通常0.1%-2%）
• 特征维度极高（可能数亿维）
• 数据量巨大（每天数十亿展示）
• 需要实时预测（毫秒级）
```

### **逻辑回归模型**

CTR预测最基础的模型是**逻辑回归（Logistic Regression, LR）**：

$$P(click=1|x) = \sigma(w^T x) = \frac{1}{1+e^{-w^T x}}$$

其中：
- $x$：特征向量
- $w$：模型参数
- $\sigma$：Sigmoid函数

```
为什么用逻辑回归？

优点：
✅ 可解释性强
✅ 训练速度快
✅ 线上预测速度快
✅ 支持大规模稀疏特征

缺点：
❌ 需要人工特征工程
❌ 难以捕捉特征交叉
```

---

## 🔧 特征工程

### **特征类型**

```
┌─────────────────────────────────────────────────────────────────┐
│                    CTR预测特征类型                                │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   广告侧特征 t(a)                                               │
│   ├── 广告主ID                                                  │
│   ├── 广告计划ID                                                │
│   ├── 广告组ID                                                  │
│   ├── 创意ID                                                    │
│   ├── 广告类型（品牌/效果）                                      │
│   └── 行业类别                                                  │
│                                                                 │
│   用户侧特征 t(u)                                               │
│   ├── 用户ID/Cookie                                             │
│   ├── 性别、年龄                                                │
│   ├── 兴趣标签                                                  │
│   ├── 历史点击行为                                              │
│   └── 设备信息                                                  │
│                                                                 │
│   上下文特征 t(c)                                               │
│   ├── 广告位ID                                                  │
│   ├── 页面URL/频道                                              │
│   ├── 时间（小时、星期几）                                       │
│   ├── 地域                                                      │
│   └── 设备类型                                                  │
│                                                                 │
│   交叉特征 t(a,u), t(a,c), t(u,c)                               │
│   ├── 用户×广告类别                                             │
│   ├── 广告位×广告主                                             │
│   └── 用户×时间段                                               │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### **特征示例**

```
一次广告展示的特征表示：

原始信息：
• 广告主：某汽车品牌
• 用户：25岁男性，汽车兴趣
• 广告位：某门户首页
• 时间：周一晚上8点

特征化后（One-Hot编码）：
{
  "advertiser_id=12345": 1,
  "user_gender=male": 1,
  "user_age_bucket=25-30": 1,
  "user_interest=auto": 1,
  "ad_position=portal_homepage": 1,
  "hour=20": 1,
  "weekday=monday": 1,
  "advertiser_id=12345 × user_interest=auto": 1,  // 交叉特征
  ...
}

特征维度可能达到数千万甚至数亿
```

---

## 📈 静态特征 vs 动态特征

### **静态特征**

```
静态特征：值为0或1的指示特征

示例：
• user_gender=male → 1
• ad_category=auto → 1
• user_interest=auto AND ad_category=auto → 1（交叉特征）

特点：
• 需要为每个特征学习一个权重
• 特征数量随组合爆炸式增长
```

### **动态特征**

```
动态特征：用历史统计值作为特征

示例：
• 该广告过去7天的CTR = 1.5%
• 该用户在汽车类广告上的历史CTR = 2.0%
• 该广告位过去7天的平均CTR = 0.8%

优势：
• 自动捕捉动态变化
• 特征值更有区分度
• 减少特征数量
```

### **CoEC（Click on Expected Click）**

```
问题：位置偏差

不同广告位的CTR差异巨大：
• 首屏广告位 CTR = 2%
• 页面底部广告位 CTR = 0.1%

如果直接用历史CTR，位置好的广告会被高估

解决：CoEC

CoEC = 实际点击数 / 期望点击数

期望点击数 = 根据位置、时间等偏差因素预估的点击数

CoEC去除了位置等因素的影响，更准确反映广告本身的质量
```

---

## 🔄 模型演进

### **发展历程**

```
CTR预测模型演进：

   LR               FM               Deep Learning
    │                │                     │
    ▼                ▼                     ▼
┌────────┐    ┌────────────┐    ┌───────────────────┐
│线性模型│ ──▶│ 特征交叉    │ ──▶│  深度学习          │
│        │    │ 自动学习    │    │  自动特征学习      │
└────────┘    └────────────┘    └───────────────────┘
   2010s        2012-2015         2016-至今

代表模型：
• LR（逻辑回归）
• GBDT + LR
• FM（Factorization Machine）
• FFM
• Wide & Deep
• DeepFM
• DIN（Deep Interest Network）
```

### **主要模型介绍**

#### **1. FM（Factorization Machine）**

```
FM 解决的问题：特征交叉

LR的问题：
• 需要人工构造交叉特征
• 高阶交叉特征数量爆炸

FM的解决方案：
• 为每个特征学习一个隐向量
• 用隐向量的内积表示特征交叉

公式：
y = w₀ + Σwᵢxᵢ + Σ<vᵢ,vⱼ>xᵢxⱼ

其中 <vᵢ,vⱼ> 是两个隐向量的内积
```

#### **2. Wide & Deep**

```
┌─────────────────────────────────────────────────────────────────┐
│                  Wide & Deep 架构                                │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│                       ┌─────────────┐                          │
│                       │   Output    │                          │
│                       └──────┬──────┘                          │
│                              │                                  │
│              ┌───────────────┴───────────────┐                  │
│              │                               │                  │
│      ┌───────┴───────┐             ┌─────────┴─────────┐       │
│      │     Wide      │             │       Deep        │       │
│      │   (线性模型)   │             │   (深度网络)       │       │
│      │               │             │                   │       │
│      │  记忆能力      │             │    泛化能力        │       │
│      │  交叉特征      │             │    自动特征学习    │       │
│      └───────────────┘             └───────────────────┘       │
│                                                                 │
│                         输入特征                                │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘

Wide部分：处理人工交叉特征，保持记忆能力
Deep部分：深度网络自动学习特征，提供泛化能力
```

#### **3. DeepFM**

```
DeepFM = FM + Deep Network

优势：
• FM部分自动学习二阶特征交叉
• Deep部分学习高阶特征交叉
• 不需要人工特征工程
```

---

## ⚙️ 工程实现

### **训练流程**

```
┌─────────────────────────────────────────────────────────────────┐
│                    CTR模型训练流程                                │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   数据收集                                                       │
│      └── 收集展示、点击日志                                      │
│      └── 过滤异常数据（作弊、机器流量）                           │
│                                                                 │
│         ▼                                                       │
│                                                                 │
│   样本处理                                                       │
│      └── 正样本：有点击的展示                                    │
│      └── 负样本：无点击的展示                                    │
│      └── 负采样：因为负样本太多，通常需要下采样                   │
│                                                                 │
│         ▼                                                       │
│                                                                 │
│   特征工程                                                       │
│      └── 特征提取                                               │
│      └── 特征编码（One-Hot, Embedding等）                       │
│      └── 特征归一化                                             │
│                                                                 │
│         ▼                                                       │
│                                                                 │
│   模型训练                                                       │
│      └── 分布式训练（Spark, TensorFlow等）                       │
│      └── 超参数调优                                             │
│                                                                 │
│         ▼                                                       │
│                                                                 │
│   模型评估                                                       │
│      └── AUC, LogLoss                                          │
│      └── 线下A/B测试                                            │
│                                                                 │
│         ▼                                                       │
│                                                                 │
│   模型上线                                                       │
│      └── 模型压缩、剪枝                                         │
│      └── 在线服务部署                                           │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### **在线预测**

```
在线预测要求：

延迟要求：
• 单次预测 < 10ms
• 包括特征查询、模型计算

吞吐要求：
• QPS 可能达到数十万甚至百万

解决方案：
• 模型简化（剪枝、量化）
• 特征缓存
• GPU/TPU加速
• 分布式服务
```

---

## 📊 模型评估

### **评估指标**

#### **1. AUC（Area Under Curve）**

```
AUC 衡量的是排序能力：

定义：随机取一个正样本和一个负样本，模型给正样本的分数
     高于负样本的概率

解释：
• AUC = 0.5：随机猜测
• AUC = 0.7：一般
• AUC = 0.8：较好
• AUC = 0.9：很好

注意：
AUC高不代表预测值准确，只代表排序正确
```

#### **2. LogLoss**

```
LogLoss 衡量预测值的准确性：

公式：
LogLoss = -1/N × Σ[yᵢlog(pᵢ) + (1-yᵢ)log(1-pᵢ)]

• yᵢ：实际标签（0或1）
• pᵢ：预测的点击概率

LogLoss越低越好
```

### **ROC曲线**

```
ROC曲线示例：

True Positive Rate (召回率)
  │
1 │         ●●●●●●●●●●●
  │      ●●●
  │    ●●
  │   ●
  │  ●
  │ ●
  │●
  └───────────────────────▶ False Positive Rate
  0                       1

• 曲线越靠近左上角越好
• 对角线代表随机猜测
• 曲线下面积 = AUC
```

---

## 🔄 模型校准

### **为什么需要校准？**

```
问题：样本不均衡导致的偏差

原始数据：
• 正样本（点击）：100万
• 负样本（未点击）：1亿

通常会做负采样：
• 负样本下采样到1000万

问题：
• 模型学到的是采样后的分布
• 预测值会偏高

解决：
• 模型校准（Calibration）
```

### **校准方法**

```
常用校准公式：

q = p / (p + (1-p)/w)

其中：
• p：模型预测值
• w：负样本采样比例
• q：校准后的预测值

示例：
• 采样比例 w = 0.1（保留10%负样本）
• 模型预测 p = 0.5
• 校准后 q = 0.5 / (0.5 + 0.5/0.1) = 0.091
```

---

## 🧪 A/B测试

### **为什么需要A/B测试？**

```
离线指标 ≠ 线上效果

可能出现的情况：
• AUC提升0.5%，但线上收入没变化
• AUC持平，但线上收入提升3%

原因：
• 离线数据分布与线上不同
• 离线指标没考虑所有因素
• 模型可能只在部分场景有效

因此，必须通过线上A/B测试验证
```

### **A/B测试设计**

```
┌─────────────────────────────────────────────────────────────────┐
│                    A/B测试设计                                   │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│            全量流量                                              │
│               │                                                 │
│       ┌───────┴───────┐                                        │
│       │               │                                         │
│       ▼               ▼                                         │
│   ┌───────┐      ┌───────┐                                     │
│   │对照组  │      │实验组  │                                     │
│   │  50%  │      │  50%  │                                     │
│   │旧模型 │      │新模型  │                                     │
│   └───────┘      └───────┘                                     │
│       │               │                                         │
│       ▼               ▼                                         │
│   收集数据         收集数据                                      │
│       │               │                                         │
│       └───────┬───────┘                                        │
│               │                                                 │
│               ▼                                                 │
│         统计显著性检验                                           │
│               │                                                 │
│               ▼                                                 │
│         决策：上线/不上线                                         │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘

观察指标：
• CTR变化
• 收入变化
• 用户体验（跳出率等）
```

---

## 🎓 本章小结

### **核心要点**

1. **CTR预测**：广告系统的核心，决定广告排序
2. **特征工程**：广告、用户、上下文特征+交叉特征
3. **模型演进**：LR → FM → Deep Learning
4. **工程挑战**：大规模、低延迟、高并发

### **关键技术点**

| 技术点 | 说明 |
|-------|------|
| 动态特征 | 用历史CTR作为特征 |
| CoEC | 消除位置偏差 |
| 负采样 | 处理样本不均衡 |
| 模型校准 | 修正采样带来的偏差 |
| A/B测试 | 验证线上效果 |

### **思考题**

1. 为什么搜索广告的CTR远高于展示广告？
2. 如何处理新广告的冷启动问题？
3. 深度学习模型相比LR有什么优缺点？

---

## 📚 延伸阅读

- [06_受众定向技术](./06_受众定向技术.md) - 了解特征来源
- [08_广告系统架构](./08_广告系统架构.md) - 了解系统架构
- [03_搜索与竞价广告](./03_搜索与竞价广告.md) - 了解eCPM排序

---

*下一章：[广告系统架构](./08_广告系统架构.md)*

